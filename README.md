# Introduction

The goal of the project is given an online comment, determine the probability for each category above that the comment falls into said category.  [Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/).

 Six types of toxicity of comments were given as follows:
- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate

## Status of the Project
Python notebooks have been using Google Colab.

# Data Pipeline


# Models


# References
